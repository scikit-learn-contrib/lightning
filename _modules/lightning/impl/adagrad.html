
<!DOCTYPE html>


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>lightning.impl.adagrad &mdash; lightning dev documentation</title>
    
    <link rel="stylesheet" href="../../../_static/basic.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/lightning.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/bootstrap.min.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/bootstrap-3.3.4/css/bootstrap.min.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/bootstrap-3.3.4/css/bootstrap-theme.min.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/bootstrap-sphinx.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../../',
        VERSION:     'dev',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../../_static/doctools.js"></script>
    <script type="text/javascript" src="../../../_static/js/jquery-1.11.0.min.js"></script>
    <script type="text/javascript" src="../../../_static/js/jquery-fix.js"></script>
    <script type="text/javascript" src="../../../_static/bootstrap-3.3.4/js/bootstrap.min.js"></script>
    <script type="text/javascript" src="../../../_static/bootstrap-sphinx.js"></script>
    <link rel="top" title="lightning dev documentation" href="../../../index.html" />
    <link rel="up" title="Module code" href="../../index.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">

  </head>
  <body role="document">

  <div id="navbar" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="../../../index.html">
          lightning</a>
        <span class="navbar-text navbar-version pull-left"><b>dev</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
                <li><a href="../../../intro.html">Introduction</a></li>
                <li><a href="../../../references.html">References</a></li>
                <li><a href="../../../auto_examples/index.html">Examples</a></li>
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="../../../index.html">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"><ul>
<li class="toctree-l1"><a class="reference internal" href="../../../auto_examples/index.html">Examples</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../auto_examples/plot_1d_total_variation.html">Signal recovery by 1D total variation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../auto_examples/plot_sgd_loss_functions.html">SGD: Convex Loss Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../auto_examples/plot_robust_regression.html">Robust regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../auto_examples/trace.html">Trace norm</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../auto_examples/plot_sample_weight.html">SAGA: Weighted samples</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../auto_examples/document_classification_news20.html">Classification of text documents</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../auto_examples/plot_svrg.html">Sensitivity to hyper-parameters in SVRG</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../auto_examples/plot_sparse_non_linear.html">Sparse non-linear classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../auto_examples/plot_l2_solvers.html">L2 solver comparison</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../references.html">Classification</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/lightning.classification.AdaGradClassifier.html">lightning.classification.AdaGradClassifier</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/lightning.classification.CDClassifier.html">lightning.classification.CDClassifier</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/lightning.classification.FistaClassifier.html">lightning.classification.FistaClassifier</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/lightning.classification.KernelSVC.html">lightning.classification.KernelSVC</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/lightning.classification.LinearSVC.html">lightning.classification.LinearSVC</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/lightning.classification.SDCAClassifier.html">lightning.classification.SDCAClassifier</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/lightning.classification.SAGClassifier.html">lightning.classification.SAGClassifier</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/lightning.classification.SAGAClassifier.html">lightning.classification.SAGAClassifier</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/lightning.classification.SGDClassifier.html">lightning.classification.SGDClassifier</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/lightning.classification.SVRGClassifier.html">lightning.classification.SVRGClassifier</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../references.html#regression">Regression</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/lightning.regression.AdaGradRegressor.html">lightning.regression.AdaGradRegressor</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/lightning.regression.CDRegressor.html">lightning.regression.CDRegressor</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/lightning.regression.FistaRegressor.html">lightning.regression.FistaRegressor</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/lightning.regression.LinearSVR.html">lightning.regression.LinearSVR</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/lightning.regression.SAGRegressor.html">lightning.regression.SAGRegressor</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/lightning.regression.SAGARegressor.html">lightning.regression.SAGARegressor</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/lightning.regression.SDCARegressor.html">lightning.regression.SDCARegressor</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/lightning.regression.SGDRegressor.html">lightning.regression.SGDRegressor</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/lightning.regression.SVRGRegressor.html">lightning.regression.SVRGRegressor</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../references.html#ranking">Ranking</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/lightning.ranking.PRank.html">lightning.ranking.PRank</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/lightning.ranking.KernelPRank.html">lightning.ranking.KernelPRank</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../intro.html">Introduction</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../intro.html#primal-coordinate-descent">Primal coordinate descent</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../intro.html#dual-coordinate-ascent">Dual coordinate ascent</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../intro.html#fista">FISTA</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../intro.html#stochastic-gradient-method-sgd">Stochastic gradient method (SGD)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../intro.html#adagrad">AdaGrad</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../intro.html#stochastic-averaged-gradient-sag-and-saga">Stochastic averaged gradient (SAG and SAGA)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../intro.html#stochastic-variance-reduced-gradient-svrg">Stochastic variance-reduced gradient (SVRG)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../intro.html#prank">PRank</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/index.html">Examples</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../auto_examples/plot_1d_total_variation.html">Signal recovery by 1D total variation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../auto_examples/plot_sgd_loss_functions.html">SGD: Convex Loss Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../auto_examples/plot_robust_regression.html">Robust regression</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../auto_examples/trace.html">Trace norm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../auto_examples/plot_sample_weight.html">SAGA: Weighted samples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../auto_examples/document_classification_news20.html">Classification of text documents</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../auto_examples/plot_svrg.html">Sensitivity to hyper-parameters in SVRG</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../auto_examples/plot_sparse_non_linear.html">Sparse non-linear classification</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../auto_examples/plot_l2_solvers.html">L2 solver comparison</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../references.html">Classification</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../generated/lightning.classification.AdaGradClassifier.html">lightning.classification.AdaGradClassifier</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../generated/lightning.classification.CDClassifier.html">lightning.classification.CDClassifier</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../generated/lightning.classification.FistaClassifier.html">lightning.classification.FistaClassifier</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../generated/lightning.classification.KernelSVC.html">lightning.classification.KernelSVC</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../generated/lightning.classification.LinearSVC.html">lightning.classification.LinearSVC</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../generated/lightning.classification.SDCAClassifier.html">lightning.classification.SDCAClassifier</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../generated/lightning.classification.SAGClassifier.html">lightning.classification.SAGClassifier</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../generated/lightning.classification.SAGAClassifier.html">lightning.classification.SAGAClassifier</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../generated/lightning.classification.SGDClassifier.html">lightning.classification.SGDClassifier</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../generated/lightning.classification.SVRGClassifier.html">lightning.classification.SVRGClassifier</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../references.html#regression">Regression</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../generated/lightning.regression.AdaGradRegressor.html">lightning.regression.AdaGradRegressor</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../generated/lightning.regression.CDRegressor.html">lightning.regression.CDRegressor</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../generated/lightning.regression.FistaRegressor.html">lightning.regression.FistaRegressor</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../generated/lightning.regression.LinearSVR.html">lightning.regression.LinearSVR</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../generated/lightning.regression.SAGRegressor.html">lightning.regression.SAGRegressor</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../generated/lightning.regression.SAGARegressor.html">lightning.regression.SAGARegressor</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../generated/lightning.regression.SDCARegressor.html">lightning.regression.SDCARegressor</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../generated/lightning.regression.SGDRegressor.html">lightning.regression.SGDRegressor</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../generated/lightning.regression.SVRGRegressor.html">lightning.regression.SVRGRegressor</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../references.html#ranking">Ranking</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../generated/lightning.ranking.PRank.html">lightning.ranking.PRank</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../generated/lightning.ranking.KernelPRank.html">lightning.ranking.KernelPRank</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</ul>
</li>
              
            
            
            
            
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="../../../search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container content-container">
  
  <h1>Source code for lightning.impl.adagrad</h1><div class="highlight"><pre>
<span></span><span class="c1"># Author: Mathieu Blondel</span>
<span class="c1"># License: BSD</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">sklearn.utils</span> <span class="kn">import</span> <span class="n">check_random_state</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelBinarizer</span>
<span class="kn">from</span> <span class="nn">sklearn.externals.six.moves</span> <span class="kn">import</span> <span class="nb">xrange</span>

<span class="kn">from</span> <span class="nn">.base</span> <span class="kn">import</span> <span class="n">BaseClassifier</span><span class="p">,</span> <span class="n">BaseRegressor</span>
<span class="kn">from</span> <span class="nn">.dataset_fast</span> <span class="kn">import</span> <span class="n">get_dataset</span>
<span class="kn">from</span> <span class="nn">.adagrad_fast</span> <span class="kn">import</span> <span class="n">_adagrad_fit</span>

<span class="kn">from</span> <span class="nn">.sgd_fast</span> <span class="kn">import</span> <span class="n">ModifiedHuber</span>
<span class="kn">from</span> <span class="nn">.sgd_fast</span> <span class="kn">import</span> <span class="n">Hinge</span>
<span class="kn">from</span> <span class="nn">.sgd_fast</span> <span class="kn">import</span> <span class="n">SmoothHinge</span>
<span class="kn">from</span> <span class="nn">.sgd_fast</span> <span class="kn">import</span> <span class="n">SquaredHinge</span>
<span class="kn">from</span> <span class="nn">.sgd_fast</span> <span class="kn">import</span> <span class="n">Log</span>
<span class="kn">from</span> <span class="nn">.sgd_fast</span> <span class="kn">import</span> <span class="n">SquaredLoss</span>
<span class="kn">from</span> <span class="nn">.sgd_fast</span> <span class="kn">import</span> <span class="n">EpsilonInsensitive</span>
<span class="kn">from</span> <span class="nn">.sgd_fast</span> <span class="kn">import</span> <span class="n">Huber</span>


<span class="k">class</span> <span class="nc">_BaseAdagrad</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">_fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">):</span>
        <span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">rng</span> <span class="o">=</span> <span class="n">check_random_state</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">)</span>
        <span class="n">n_vectors</span> <span class="o">=</span> <span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">ds</span> <span class="o">=</span> <span class="n">get_dataset</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;c&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">coef_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_vectors</span><span class="p">,</span> <span class="n">n_features</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">g_sum_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_vectors</span><span class="p">,</span> <span class="n">n_features</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">g_norms_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_vectors</span><span class="p">,</span> <span class="n">n_features</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

        <span class="n">delta</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">alpha1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">l1_ratio</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span>
        <span class="n">alpha2</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">l1_ratio</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_loss</span><span class="p">()</span>
        <span class="n">n_calls</span> <span class="o">=</span> <span class="n">n_samples</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_calls</span> <span class="ow">is</span> <span class="bp">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_calls</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">n_vectors</span><span class="p">):</span>
            <span class="n">_adagrad_fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ds</span><span class="p">,</span> <span class="n">Y</span><span class="p">[:,</span> <span class="n">i</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">coef_</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">g_sum_</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
                         <span class="bp">self</span><span class="o">.</span><span class="n">g_norms_</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">loss</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">eta</span><span class="p">,</span> <span class="n">delta</span><span class="p">,</span> <span class="n">alpha1</span><span class="p">,</span>
                         <span class="n">alpha2</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_iter</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">shuffle</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">callback</span><span class="p">,</span>
                         <span class="n">n_calls</span><span class="p">,</span> <span class="n">rng</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span>


<div class="viewcode-block" id="AdaGradClassifier"><a class="viewcode-back" href="../../../generated/lightning.classification.AdaGradClassifier.html#lightning.classification.AdaGradClassifier">[docs]</a><span class="k">class</span> <span class="nc">AdaGradClassifier</span><span class="p">(</span><span class="n">BaseClassifier</span><span class="p">,</span> <span class="n">_BaseAdagrad</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Estimator for learning linear classifiers by AdaGrad.</span>

<span class="sd">    Solves the following objective:</span>

<span class="sd">        minimize_w  1 / n_samples * \sum_i loss(w^T x_i, y_i)</span>
<span class="sd">                    + alpha * l1_ratio * ||w||_1</span>
<span class="sd">                    + alpha * (1 - l1_ratio) * 0.5 * ||w||^2_2</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="AdaGradClassifier.__init__"><a class="viewcode-back" href="../../../generated/lightning.classification.AdaGradClassifier.html#lightning.classification.AdaGradClassifier.__init__">[docs]</a>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">eta</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">l1_ratio</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s2">&quot;hinge&quot;</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
                 <span class="n">n_iter</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">n_calls</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
                 <span class="n">random_state</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eta</span> <span class="o">=</span> <span class="n">eta</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">l1_ratio</span> <span class="o">=</span> <span class="n">l1_ratio</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">=</span> <span class="n">gamma</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_iter</span> <span class="o">=</span> <span class="n">n_iter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">shuffle</span> <span class="o">=</span> <span class="n">shuffle</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">callback</span> <span class="o">=</span> <span class="n">callback</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_calls</span> <span class="o">=</span> <span class="n">n_calls</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">random_state</span></div>

    <span class="k">def</span> <span class="nf">_get_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">losses</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;modified_huber&quot;</span><span class="p">:</span> <span class="n">ModifiedHuber</span><span class="p">(),</span>
            <span class="s2">&quot;hinge&quot;</span><span class="p">:</span> <span class="n">Hinge</span><span class="p">(</span><span class="mf">1.0</span><span class="p">),</span>
            <span class="s2">&quot;smooth_hinge&quot;</span><span class="p">:</span> <span class="n">SmoothHinge</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gamma</span><span class="p">),</span>
            <span class="s2">&quot;squared_hinge&quot;</span><span class="p">:</span> <span class="n">SquaredHinge</span><span class="p">(</span><span class="mf">1.0</span><span class="p">),</span>
            <span class="s2">&quot;perceptron&quot;</span><span class="p">:</span> <span class="n">Hinge</span><span class="p">(</span><span class="mf">0.0</span><span class="p">),</span>
            <span class="s2">&quot;log&quot;</span><span class="p">:</span> <span class="n">Log</span><span class="p">(),</span>
            <span class="s2">&quot;squared&quot;</span><span class="p">:</span> <span class="n">SquaredLoss</span><span class="p">(),</span>
        <span class="p">}</span>
        <span class="k">return</span> <span class="n">losses</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_set_label_transformers</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asfortranarray</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">label_binarizer_</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">y</span><span class="p">),</span>
                              <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span></div>


<div class="viewcode-block" id="AdaGradRegressor"><a class="viewcode-back" href="../../../generated/lightning.regression.AdaGradRegressor.html#lightning.classification.AdaGradRegressor">[docs]</a><span class="k">class</span> <span class="nc">AdaGradRegressor</span><span class="p">(</span><span class="n">BaseRegressor</span><span class="p">,</span> <span class="n">_BaseAdagrad</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Estimator for learning linear regressors by AdaGrad.</span>

<span class="sd">    Solves the following objective:</span>

<span class="sd">        minimize_w  1 / n_samples * \sum_i loss(w^T x_i, y_i)</span>
<span class="sd">                    + alpha * l1_ratio * ||w||_1</span>
<span class="sd">                    + alpha * (1 - l1_ratio) * 0.5 * ||w||^2_2</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="AdaGradRegressor.__init__"><a class="viewcode-back" href="../../../generated/lightning.regression.AdaGradRegressor.html#lightning.classification.AdaGradRegressor.__init__">[docs]</a>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">eta</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">l1_ratio</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s2">&quot;squared&quot;</span><span class="p">,</span>
                 <span class="n">gamma</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_iter</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
                 <span class="n">n_calls</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eta</span> <span class="o">=</span> <span class="n">eta</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">l1_ratio</span> <span class="o">=</span> <span class="n">l1_ratio</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">=</span> <span class="n">gamma</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="n">epsilon</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_iter</span> <span class="o">=</span> <span class="n">n_iter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">shuffle</span> <span class="o">=</span> <span class="n">shuffle</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">callback</span> <span class="o">=</span> <span class="n">callback</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_calls</span> <span class="o">=</span> <span class="n">n_calls</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">random_state</span></div>

    <span class="k">def</span> <span class="nf">_get_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">losses</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;squared&quot;</span><span class="p">:</span> <span class="n">SquaredLoss</span><span class="p">(),</span>
            <span class="s2">&quot;huber&quot;</span><span class="p">:</span> <span class="n">Huber</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span><span class="p">),</span>
            <span class="s2">&quot;epsilon_insensitive&quot;</span><span class="p">:</span> <span class="n">EpsilonInsensitive</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span><span class="p">),</span>
            <span class="s2">&quot;absolute&quot;</span><span class="p">:</span> <span class="n">EpsilonInsensitive</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="p">}</span>
        <span class="k">return</span> <span class="n">losses</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">outputs_2d_</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span>
        <span class="n">Y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">outputs_2d_</span> <span class="k">else</span> <span class="n">y</span>
        <span class="n">Y</span> <span class="o">=</span> <span class="n">Y</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span></div>
</pre></div>

</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
    </p>
    <p>
        &copy; Copyright Mathieu Blondel.<br/>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.3.5.<br/>
    </p>
  </div>
</footer>
  </body>
</html>