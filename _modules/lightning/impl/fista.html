<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>lightning.impl.fista &#8212; lightning 0.6.1.dev0 documentation</title>
    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/bootstrap-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/lightning.css" />
    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">
<script type="text/javascript" src="../../../_static/js/jquery-1.11.0.min.js "></script>
<script type="text/javascript" src="../../../_static/js/jquery-fix.js "></script>
<script type="text/javascript" src="../../../_static/bootstrap-3.3.7/js/bootstrap.min.js "></script>
<script type="text/javascript" src="../../../_static/bootstrap-sphinx.js "></script>

  </head><body>

  <div id="navbar" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="../../../index.html">
          lightning</a>
        <span class="navbar-text navbar-version pull-left"><b></b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
                <li><a href="../../../intro.html">Introduction</a></li>
                <li><a href="../../../references.html">References</a></li>
                <li><a href="../../../auto_examples/index.html">Examples</a></li>
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="../../../index.html">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"><ul>
<li class="toctree-l1"><a class="reference internal" href="../../../auto_examples/index.html">Examples</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../auto_examples/plot_sgd_loss_functions.html">SGD: Convex Loss Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../auto_examples/plot_1d_total_variation.html">Signal recovery by 1D total variation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../auto_examples/plot_robust_regression.html">Robust regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../auto_examples/trace.html">Trace norm</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../auto_examples/plot_sample_weight.html">SAGA: Weighted samples</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../auto_examples/document_classification_news20.html">Classification of text documents</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../auto_examples/plot_svrg.html">Sensitivity to hyper-parameters in SVRG</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../auto_examples/plot_sparse_non_linear.html">Sparse non-linear classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../auto_examples/plot_l2_solvers.html">L2 solver comparison</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../references.html">Classification</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/lightning.classification.AdaGradClassifier.html">lightning.classification.AdaGradClassifier</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/lightning.classification.CDClassifier.html">lightning.classification.CDClassifier</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/lightning.classification.FistaClassifier.html">lightning.classification.FistaClassifier</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/lightning.classification.KernelSVC.html">lightning.classification.KernelSVC</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/lightning.classification.LinearSVC.html">lightning.classification.LinearSVC</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/lightning.classification.SDCAClassifier.html">lightning.classification.SDCAClassifier</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/lightning.classification.SAGClassifier.html">lightning.classification.SAGClassifier</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/lightning.classification.SAGAClassifier.html">lightning.classification.SAGAClassifier</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/lightning.classification.SGDClassifier.html">lightning.classification.SGDClassifier</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/lightning.classification.SVRGClassifier.html">lightning.classification.SVRGClassifier</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../references.html#regression">Regression</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/lightning.regression.AdaGradRegressor.html">lightning.regression.AdaGradRegressor</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/lightning.regression.CDRegressor.html">lightning.regression.CDRegressor</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/lightning.regression.FistaRegressor.html">lightning.regression.FistaRegressor</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/lightning.regression.LinearSVR.html">lightning.regression.LinearSVR</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/lightning.regression.SAGRegressor.html">lightning.regression.SAGRegressor</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/lightning.regression.SAGARegressor.html">lightning.regression.SAGARegressor</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/lightning.regression.SDCARegressor.html">lightning.regression.SDCARegressor</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/lightning.regression.SGDRegressor.html">lightning.regression.SGDRegressor</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/lightning.regression.SVRGRegressor.html">lightning.regression.SVRGRegressor</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../references.html#ranking">Ranking</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/lightning.ranking.PRank.html">lightning.ranking.PRank</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/lightning.ranking.KernelPRank.html">lightning.ranking.KernelPRank</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../intro.html">Introduction</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../intro.html#primal-coordinate-descent">Primal coordinate descent</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../intro.html#dual-coordinate-ascent">Dual coordinate ascent</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../intro.html#fista">FISTA</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../intro.html#stochastic-gradient-method-sgd">Stochastic gradient method (SGD)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../intro.html#adagrad">AdaGrad</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../intro.html#stochastic-averaged-gradient-sag-and-saga">Stochastic averaged gradient (SAG and SAGA)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../intro.html#stochastic-variance-reduced-gradient-svrg">Stochastic variance-reduced gradient (SVRG)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../intro.html#prank">PRank</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/index.html">Examples</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../auto_examples/plot_sgd_loss_functions.html">SGD: Convex Loss Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../auto_examples/plot_1d_total_variation.html">Signal recovery by 1D total variation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../auto_examples/plot_robust_regression.html">Robust regression</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../auto_examples/trace.html">Trace norm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../auto_examples/plot_sample_weight.html">SAGA: Weighted samples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../auto_examples/document_classification_news20.html">Classification of text documents</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../auto_examples/plot_svrg.html">Sensitivity to hyper-parameters in SVRG</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../auto_examples/plot_sparse_non_linear.html">Sparse non-linear classification</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../auto_examples/plot_l2_solvers.html">L2 solver comparison</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../references.html">Classification</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../generated/lightning.classification.AdaGradClassifier.html">lightning.classification.AdaGradClassifier</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../generated/lightning.classification.CDClassifier.html">lightning.classification.CDClassifier</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../generated/lightning.classification.FistaClassifier.html">lightning.classification.FistaClassifier</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../generated/lightning.classification.KernelSVC.html">lightning.classification.KernelSVC</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../generated/lightning.classification.LinearSVC.html">lightning.classification.LinearSVC</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../generated/lightning.classification.SDCAClassifier.html">lightning.classification.SDCAClassifier</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../generated/lightning.classification.SAGClassifier.html">lightning.classification.SAGClassifier</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../generated/lightning.classification.SAGAClassifier.html">lightning.classification.SAGAClassifier</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../generated/lightning.classification.SGDClassifier.html">lightning.classification.SGDClassifier</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../generated/lightning.classification.SVRGClassifier.html">lightning.classification.SVRGClassifier</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../references.html#regression">Regression</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../generated/lightning.regression.AdaGradRegressor.html">lightning.regression.AdaGradRegressor</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../generated/lightning.regression.CDRegressor.html">lightning.regression.CDRegressor</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../generated/lightning.regression.FistaRegressor.html">lightning.regression.FistaRegressor</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../generated/lightning.regression.LinearSVR.html">lightning.regression.LinearSVR</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../generated/lightning.regression.SAGRegressor.html">lightning.regression.SAGRegressor</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../generated/lightning.regression.SAGARegressor.html">lightning.regression.SAGARegressor</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../generated/lightning.regression.SDCARegressor.html">lightning.regression.SDCARegressor</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../generated/lightning.regression.SGDRegressor.html">lightning.regression.SGDRegressor</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../generated/lightning.regression.SVRGRegressor.html">lightning.regression.SVRGRegressor</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../references.html#ranking">Ranking</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../generated/lightning.ranking.PRank.html">lightning.ranking.PRank</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../generated/lightning.ranking.KernelPRank.html">lightning.ranking.KernelPRank</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</ul>
</li>
              
            
            
            
            
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="../../../search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
    <div class="body col-md-12 content" role="main">
      
  <h1>Source code for lightning.impl.fista</h1><div class="highlight"><pre>
<span></span><span class="c1"># Author: Mathieu Blondel</span>
<span class="c1"># License: BSD</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">sklearn.utils.extmath</span> <span class="kn">import</span> <span class="n">safe_sparse_dot</span>

<span class="kn">from</span> <span class="nn">.base</span> <span class="kn">import</span> <span class="n">BaseClassifier</span><span class="p">,</span> <span class="n">BaseRegressor</span>

<span class="kn">from</span> <span class="nn">.dataset_fast</span> <span class="kn">import</span> <span class="n">get_dataset</span>

<span class="kn">from</span> <span class="nn">.loss_fast</span> <span class="kn">import</span> <span class="n">Squared</span>
<span class="kn">from</span> <span class="nn">.loss_fast</span> <span class="kn">import</span> <span class="n">SquaredHinge</span>
<span class="kn">from</span> <span class="nn">.loss_fast</span> <span class="kn">import</span> <span class="n">MulticlassSquaredHinge</span>
<span class="kn">from</span> <span class="nn">.loss_fast</span> <span class="kn">import</span> <span class="n">MulticlassLog</span>

<span class="kn">from</span> <span class="nn">.penalty</span> <span class="kn">import</span> <span class="n">L1Penalty</span>
<span class="kn">from</span> <span class="nn">.penalty</span> <span class="kn">import</span> <span class="n">L1L2Penalty</span>
<span class="kn">from</span> <span class="nn">.penalty</span> <span class="kn">import</span> <span class="n">TracePenalty</span>
<span class="kn">from</span> <span class="nn">.penalty</span> <span class="kn">import</span> <span class="n">SimplexConstraint</span>
<span class="kn">from</span> <span class="nn">.penalty</span> <span class="kn">import</span> <span class="n">L1BallConstraint</span>
<span class="kn">from</span> <span class="nn">.penalty</span> <span class="kn">import</span> <span class="n">TotalVariation1DPenalty</span>


<span class="k">class</span> <span class="nc">_BaseFista</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">_get_penalty</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">penalty</span><span class="p">,</span> <span class="s1">&#39;projection&#39;</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">penalty</span>
        <span class="n">penalties</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;l1&quot;</span><span class="p">:</span> <span class="n">L1Penalty</span><span class="p">(),</span>
            <span class="s2">&quot;l1/l2&quot;</span><span class="p">:</span> <span class="n">L1L2Penalty</span><span class="p">(),</span>
            <span class="s2">&quot;trace&quot;</span><span class="p">:</span> <span class="n">TracePenalty</span><span class="p">(),</span>
            <span class="s2">&quot;simplex&quot;</span><span class="p">:</span> <span class="n">SimplexConstraint</span><span class="p">(),</span>
            <span class="s2">&quot;l1-ball&quot;</span><span class="p">:</span> <span class="n">L1BallConstraint</span><span class="p">(),</span>
            <span class="s2">&quot;tv1d&quot;</span><span class="p">:</span> <span class="n">TotalVariation1DPenalty</span><span class="p">()</span>
        <span class="p">}</span>
        <span class="k">return</span> <span class="n">penalties</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">penalty</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">_get_objective</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">loss</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">C</span> <span class="o">*</span> <span class="n">loss</span><span class="o">.</span><span class="n">objective</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_get_regularized_objective</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">penalty</span><span class="p">,</span> <span class="n">coef</span><span class="p">):</span>
        <span class="n">obj</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_objective</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>
        <span class="n">obj</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">*</span> <span class="n">penalty</span><span class="o">.</span><span class="n">regularization</span><span class="p">(</span><span class="n">coef</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">obj</span>

    <span class="k">def</span> <span class="nf">_get_quad_approx</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">coefa</span><span class="p">,</span> <span class="n">coefb</span><span class="p">,</span> <span class="n">objb</span><span class="p">,</span> <span class="n">gradb</span><span class="p">,</span> <span class="n">L</span><span class="p">,</span> <span class="n">penalty</span><span class="p">):</span>
        <span class="n">approx</span> <span class="o">=</span> <span class="n">objb</span>
        <span class="n">diff</span> <span class="o">=</span> <span class="n">coefa</span> <span class="o">-</span> <span class="n">coefb</span>
        <span class="n">approx</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">diff</span> <span class="o">*</span> <span class="n">gradb</span><span class="p">)</span>
        <span class="n">approx</span> <span class="o">+=</span> <span class="n">L</span> <span class="o">/</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">diff</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">approx</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">*</span> <span class="n">penalty</span><span class="o">.</span><span class="n">regularization</span><span class="p">(</span><span class="n">coefa</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">approx</span>

    <span class="k">def</span> <span class="nf">_fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">n_vectors</span><span class="p">):</span>
        <span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_loss</span><span class="p">()</span>
        <span class="n">penalty</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_penalty</span><span class="p">()</span>
        <span class="n">ds</span> <span class="o">=</span> <span class="n">get_dataset</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

        <span class="n">df</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">n_vectors</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
        <span class="n">coef</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_vectors</span><span class="p">,</span> <span class="n">n_features</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
        <span class="n">coefx</span> <span class="o">=</span> <span class="n">coef</span>
        <span class="n">G</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_vectors</span><span class="p">,</span> <span class="n">n_features</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

        <span class="n">obj</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_regularized_objective</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">penalty</span><span class="p">,</span> <span class="n">coef</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_steps</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># No line search, need to use constant step size.</span>
            <span class="n">L</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">C</span> <span class="o">*</span> <span class="n">loss</span><span class="o">.</span><span class="n">lipschitz_constant</span><span class="p">(</span><span class="n">ds</span><span class="p">,</span> <span class="n">n_vectors</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Do not bother to compute the Lipschitz constant (expensive).</span>
            <span class="n">L</span> <span class="o">=</span> <span class="mf">1.0</span>

        <span class="n">t</span> <span class="o">=</span> <span class="mf">1.0</span>
        <span class="k">for</span> <span class="n">it</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span><span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Iter&quot;</span><span class="p">,</span> <span class="n">it</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">obj</span><span class="p">)</span>

            <span class="c1"># Save current values</span>
            <span class="n">t_old</span> <span class="o">=</span> <span class="n">t</span>
            <span class="n">coefx_old</span> <span class="o">=</span> <span class="n">coefx</span>

            <span class="c1"># Gradient</span>
            <span class="n">G</span><span class="o">.</span><span class="n">fill</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">ds</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">G</span><span class="p">)</span>
            <span class="n">G</span> <span class="o">*=</span> <span class="bp">self</span><span class="o">.</span><span class="n">C</span>

            <span class="c1"># Line search</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_steps</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">objb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_objective</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">tt</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_steps</span><span class="p">):</span>
                <span class="c1"># Solve</span>
                <span class="n">coefx</span> <span class="o">=</span> <span class="n">coef</span> <span class="o">-</span> <span class="n">G</span> <span class="o">/</span> <span class="n">L</span>
                <span class="n">coefx</span> <span class="o">=</span> <span class="n">penalty</span><span class="o">.</span><span class="n">projection</span><span class="p">(</span><span class="n">coefx</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">,</span> <span class="n">L</span><span class="p">)</span>

                <span class="n">dfx</span> <span class="o">=</span> <span class="n">safe_sparse_dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">coefx</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
                <span class="n">obj</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_regularized_objective</span><span class="p">(</span><span class="n">dfx</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">penalty</span><span class="p">,</span>
                                                      <span class="n">coefx</span><span class="p">)</span>
                <span class="n">approx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_quad_approx</span><span class="p">(</span><span class="n">coefx</span><span class="p">,</span> <span class="n">coef</span><span class="p">,</span> <span class="n">objb</span><span class="p">,</span> <span class="n">G</span><span class="p">,</span> <span class="n">L</span><span class="p">,</span> <span class="n">penalty</span><span class="p">)</span>

                <span class="n">accepted</span> <span class="o">=</span> <span class="n">obj</span> <span class="o">&lt;=</span> <span class="n">approx</span>

                <span class="c1"># Sufficient decrease condition</span>
                <span class="k">if</span> <span class="n">accepted</span><span class="p">:</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">&gt;=</span> <span class="mi">2</span><span class="p">:</span>
                        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accepted at&quot;</span><span class="p">,</span> <span class="n">tt</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
                    <span class="k">break</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">L</span> <span class="o">*=</span> <span class="bp">self</span><span class="o">.</span><span class="n">eta</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_steps</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">coefx</span> <span class="o">=</span> <span class="n">coef</span> <span class="o">-</span> <span class="n">G</span> <span class="o">/</span> <span class="n">L</span>
                <span class="n">coefx</span> <span class="o">=</span> <span class="n">penalty</span><span class="o">.</span><span class="n">projection</span><span class="p">(</span><span class="n">coefx</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">,</span> <span class="n">L</span><span class="p">)</span>

            <span class="n">t</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="mi">4</span> <span class="o">*</span> <span class="n">t_old</span> <span class="o">*</span> <span class="n">t_old</span><span class="p">))</span> <span class="o">/</span> <span class="mi">2</span>
            <span class="n">coef</span> <span class="o">=</span> <span class="n">coefx</span> <span class="o">+</span> <span class="p">(</span><span class="n">t_old</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">t</span> <span class="o">*</span> <span class="p">(</span><span class="n">coefx</span> <span class="o">-</span> <span class="n">coefx_old</span><span class="p">)</span>
            <span class="n">df</span> <span class="o">=</span> <span class="n">safe_sparse_dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">coef</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>

            <span class="c1"># Callback might need self.coef_.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">coef_</span> <span class="o">=</span> <span class="n">coef</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">callback</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">ret</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">callback</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">ret</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="k">break</span>

        <span class="k">return</span> <span class="bp">self</span>


<div class="viewcode-block" id="FistaClassifier"><a class="viewcode-back" href="../../../generated/lightning.classification.FistaClassifier.html#lightning.classification.FistaClassifier">[docs]</a><span class="k">class</span> <span class="nc">FistaClassifier</span><span class="p">(</span><span class="n">BaseClassifier</span><span class="p">,</span> <span class="n">_BaseFista</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Estimator for learning linear classifiers by FISTA.</span>

<span class="sd">    The objective functions considered take the form</span>

<span class="sd">    minimize F(W) = C * L(W) + alpha * R(W),</span>

<span class="sd">    where L(W) is a loss term and R(W) is a penalty term.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    loss : str, &#39;squared_hinge&#39;, &#39;log&#39;, &#39;modified_huber&#39;, &#39;squared&#39;</span>
<span class="sd">        The loss function to be used.</span>

<span class="sd">    penalty : str or Penalty object, {&#39;l2&#39;, &#39;l1&#39;, &#39;l1/l2&#39;, &#39;tv1d&#39;, &#39;simplex&#39;}</span>
<span class="sd">        The penalty or constraint to be used.</span>

<span class="sd">        - l2: ridge</span>
<span class="sd">        - l1: lasso</span>
<span class="sd">        - l1/l2: group lasso</span>
<span class="sd">        - tv1d: 1-dimensional total variation (also known as fused lasso)</span>
<span class="sd">        - simplex: simplex constraint</span>

<span class="sd">        The method can also take an arbitrary Penalty object, i.e., an instance</span>
<span class="sd">        that implements methods projection regularization method (see file penalty.py)</span>

<span class="sd">    multiclass : bool</span>
<span class="sd">        Whether to use a direct multiclass formulation (True) or one-vs-rest</span>
<span class="sd">        (False).</span>

<span class="sd">    C : float</span>
<span class="sd">        Weight of the loss term.</span>

<span class="sd">    alpha : float</span>
<span class="sd">        Weight of the penalty term.</span>

<span class="sd">    max_iter : int</span>
<span class="sd">        Maximum number of iterations to perform.</span>

<span class="sd">    max_steps : int</span>
<span class="sd">        Maximum number of steps to use during the line search.</span>

<span class="sd">    sigma : float</span>
<span class="sd">        Constant used in the line search sufficient decrease condition.</span>

<span class="sd">    eta : float</span>
<span class="sd">         Decrease factor for line-search procedure. For example, eta=2.</span>
<span class="sd">         will decrease the step size by a factor of 2 at each iteration</span>
<span class="sd">         of the line-search routine.</span>

<span class="sd">    callback : callable</span>
<span class="sd">        Callback function.</span>

<span class="sd">    verbose : int</span>
<span class="sd">        Verbosity level.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s2">&quot;squared_hinge&quot;</span><span class="p">,</span> <span class="n">penalty</span><span class="o">=</span><span class="s2">&quot;l1&quot;</span><span class="p">,</span>
                 <span class="n">multiclass</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">max_steps</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">eta</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span>
                 <span class="n">sigma</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">C</span> <span class="o">=</span> <span class="n">C</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">penalty</span> <span class="o">=</span> <span class="n">penalty</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">multiclass</span> <span class="o">=</span> <span class="n">multiclass</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span> <span class="o">=</span> <span class="n">max_iter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_steps</span> <span class="o">=</span> <span class="n">max_steps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eta</span> <span class="o">=</span> <span class="n">eta</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sigma</span> <span class="o">=</span> <span class="n">sigma</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">callback</span> <span class="o">=</span> <span class="n">callback</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>

    <span class="k">def</span> <span class="nf">_get_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">multiclass</span><span class="p">:</span>
            <span class="n">losses</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s2">&quot;squared_hinge&quot;</span><span class="p">:</span> <span class="n">MulticlassSquaredHinge</span><span class="p">(),</span>
                <span class="s2">&quot;log&quot;</span><span class="p">:</span> <span class="n">MulticlassLog</span><span class="p">(),</span>
                <span class="s2">&quot;log_margin&quot;</span><span class="p">:</span> <span class="n">MulticlassLog</span><span class="p">(</span><span class="n">margin</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="p">}</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">losses</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s2">&quot;squared_hinge&quot;</span><span class="p">:</span> <span class="n">SquaredHinge</span><span class="p">(),</span>
            <span class="p">}</span>

        <span class="k">return</span> <span class="n">losses</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">]</span>

<div class="viewcode-block" id="FistaClassifier.fit"><a class="viewcode-back" href="../../../generated/lightning.classification.FistaClassifier.html#lightning.classification.FistaClassifier.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="n">y</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">n_vectors</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set_label_transformers</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">reencode</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">multiclass</span><span class="p">:</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asfortranarray</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">label_binarizer_</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">y</span><span class="p">),</span>
                                  <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
            <span class="n">n_vectors</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">n_vectors</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="FistaRegressor"><a class="viewcode-back" href="../../../generated/lightning.regression.FistaRegressor.html#lightning.classification.FistaRegressor">[docs]</a><span class="k">class</span> <span class="nc">FistaRegressor</span><span class="p">(</span><span class="n">BaseRegressor</span><span class="p">,</span> <span class="n">_BaseFista</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Estimator for learning linear classifiers by FISTA.</span>

<span class="sd">    The objective functions considered take the form</span>

<span class="sd">    minimize F(W) = C * L(W) + alpha * R(W),</span>

<span class="sd">    where L(W) is a loss term and R(W) is a penalty term.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    penalty : str or Penalty object, {&#39;l2&#39;, &#39;l1&#39;, &#39;l1/l2&#39;, &#39;tv1d&#39;, &#39;simplex&#39;}</span>
<span class="sd">        The penalty or constraint to be used.</span>

<span class="sd">        - l2: ridge</span>
<span class="sd">        - l1: lasso</span>
<span class="sd">        - l1/l2: group lasso</span>
<span class="sd">        - tv1d: 1-dimensional total variation (also known as fussed lasso)</span>
<span class="sd">        - simplex: simplex constraint</span>

<span class="sd">        The method can also take an arbitrary Penalty object, i.e., an instance</span>
<span class="sd">        that implements methods projection regularization method (see file penalty.py)</span>


<span class="sd">    C : float</span>
<span class="sd">        Weight of the loss term.</span>

<span class="sd">    alpha : float</span>
<span class="sd">        Weight of the penalty term.</span>

<span class="sd">    max_iter : int</span>
<span class="sd">        Maximum number of iterations to perform.</span>

<span class="sd">    max_steps : int</span>
<span class="sd">        Maximum number of steps to use during the line search.</span>

<span class="sd">    sigma : float</span>
<span class="sd">        Constant used in the line search sufficient decrease condition.</span>

<span class="sd">    eta : float</span>
<span class="sd">         Decrease factor for line-search procedure. For example, eta=2.</span>
<span class="sd">         will decrease the step size by a factor of 2 at each iteration</span>
<span class="sd">         of the line-search routine.</span>

<span class="sd">    callback : callable</span>
<span class="sd">        Callback function.</span>

<span class="sd">    verbose : int</span>
<span class="sd">        Verbosity level.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">penalty</span><span class="o">=</span><span class="s2">&quot;l1&quot;</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                 <span class="n">max_steps</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">eta</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">C</span> <span class="o">=</span> <span class="n">C</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">penalty</span> <span class="o">=</span> <span class="n">penalty</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span> <span class="o">=</span> <span class="n">max_iter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_steps</span> <span class="o">=</span> <span class="n">max_steps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eta</span> <span class="o">=</span> <span class="n">eta</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sigma</span> <span class="o">=</span> <span class="n">sigma</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">callback</span> <span class="o">=</span> <span class="n">callback</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>

    <span class="k">def</span> <span class="nf">_get_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">Squared</span><span class="p">()</span>

<div class="viewcode-block" id="FistaRegressor.fit"><a class="viewcode-back" href="../../../generated/lightning.regression.FistaRegressor.html#lightning.classification.FistaRegressor.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">outputs_2d_</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span>
        <span class="n">Y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">outputs_2d_</span> <span class="k">else</span> <span class="n">y</span>
        <span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asfortranarray</span><span class="p">(</span><span class="n">Y</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">))</span>
        <span class="n">n_vectors</span> <span class="o">=</span> <span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">n_vectors</span><span class="p">)</span></div></div>
</pre></div>

    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
    </p>
    <p>
        &copy; Copyright 2021, Mathieu Blondel.<br/>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.0.2.<br/>
    </p>
  </div>
</footer>
  </body>
</html>