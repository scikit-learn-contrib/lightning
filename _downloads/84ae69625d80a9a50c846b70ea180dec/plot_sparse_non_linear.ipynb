{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Sparse non-linear classification\n\nThis examples demonstrates how to use `CDClassifier` with L1 penalty to do\nsparse non-linear classification. The trick simply consists in fitting the\nclassifier with a kernel matrix (e.g., using an RBF kernel).\n\nThere are a few interesting differences with standard kernel SVMs:\n\n1. the kernel matrix does not need to be positive semi-definite (hence the\nexpression \"kernel matrix\" above is an abuse of terminology)\n\n2. the number of \"support vectors\" will be typically smaller thanks to L1\nregularization and can be adjusted by the regularization parameter C (the\nsmaller C, the fewer the support vectors)\n\n3. the \"support vectors\" need not be located at the margin\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport pylab as pl\n\nfrom sklearn.metrics.pairwise import rbf_kernel\n\nfrom lightning.classification import CDClassifier\nfrom lightning.classification import KernelSVC\n\nnp.random.seed(0)\n\nclass SparseNonlinearClassifier(CDClassifier):\n\n    def __init__(self, gamma=1e-2, C=1, alpha=1):\n        self.gamma = gamma\n        super().__init__(C=C,\n                         alpha=alpha,\n                         loss=\"squared_hinge\",\n                         penalty=\"l1\")\n\n    def fit(self, X, y):\n        K = rbf_kernel(X, gamma=self.gamma)\n        self.X_train_ = X\n        super().fit(K, y)\n        return self\n\n    def decision_function(self, X):\n        K = rbf_kernel(X, self.X_train_, gamma=self.gamma)\n        return super().decision_function(K)\n\n\ndef gen_non_lin_separable_data():\n    mean1 = [-1, 2]\n    mean2 = [1, -1]\n    mean3 = [4, -4]\n    mean4 = [-4, 4]\n    cov = [[1.0,0.8], [0.8, 1.0]]\n    X1 = np.random.multivariate_normal(mean1, cov, 50)\n    X1 = np.vstack((X1, np.random.multivariate_normal(mean3, cov, 50)))\n    y1 = np.ones(len(X1))\n    X2 = np.random.multivariate_normal(mean2, cov, 50)\n    X2 = np.vstack((X2, np.random.multivariate_normal(mean4, cov, 50)))\n    y2 = np.ones(len(X2)) * -1\n    return X1, y1, X2, y2\n\ndef plot_contour(X, X1, X2, clf, title):\n    pl.figure()\n    pl.title(title)\n\n    # Plot instances of class 1.\n    pl.plot(X1[:,0], X1[:,1], \"ro\")\n    # Plot instances of class 2.\n    pl.plot(X2[:,0], X2[:,1], \"bo\")\n\n    # Select \"support vectors\".\n    if hasattr(clf, \"support_vectors_\"):\n        sv = clf.support_vectors_\n    else:\n        sv = X[clf.coef_.ravel() != 0]\n\n    # Plot support vectors.\n    pl.scatter(sv[:, 0], sv[:, 1], s=100, c=\"g\")\n\n    # Plot decision surface.\n    A, B = np.meshgrid(np.linspace(-6,6,50), np.linspace(-6,6,50))\n    C = np.array([[x1, x2] for x1, x2 in zip(np.ravel(A), np.ravel(B))])\n    Z = clf.decision_function(C).reshape(A.shape)\n    pl.contour(A, B, Z, [0.0], colors='k', linewidths=1, origin='lower')\n\n    pl.axis(\"tight\")\n\n# Generate synthetic data from 2 classes.\nX1, y1, X2, y2 = gen_non_lin_separable_data()\n\n# Combine them to form a training set.\nX = np.vstack((X1, X2))\ny = np.hstack((y1, y2))\n\n# Train the classifiers.\nclf = SparseNonlinearClassifier(gamma=0.1, alpha=1./0.05)\nclf.fit(X, y)\n\nclf2 = KernelSVC(gamma=0.1, kernel=\"rbf\", alpha=1e-2)\nclf2.fit(X, y)\n\n# Plot contours.\nplot_contour(X, X1, X2, clf, \"Sparse\")\nplot_contour(X, X1, X2, clf2, \"Kernel SVM\")\n\npl.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}